%
% File acl2016.tex
%
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn,
%% based on the style files for ACL-2010, which were, in turn,
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{acl2016}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{booktabs}
\usepackage{relsize}
\usepackage{multirow}
%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


%% Greit å vite:

%% Siteringer:
%% Med parentes rundt hele: \cite{Gusfield:97}
%% Eller med parentes kun rundt år:  \newcite{Gusfield:97}
%% Flere på en gang: \cite{Gusfield:97,Aho:72}


%% Fra instruksjonene, om \aclfinalcopy :

%% By uncommenting {\small\verb|\aclfinalcopy|} at the top of this document, it
%% will compile to produce an example of the camera-ready formatting; by leaving
%% it commented out, the document will be anonymized for initial submission.  When
%% you first create your submission on softconf, please fill in your submitted
%% paper ID where {\small\verb|***|} appears in the
%% {\small\verb|\def\aclpaperid{***}|} definition at the top.

%% The review process is double-blind, so do not include any author information
%% (names, addresses) when submitting a paper for review.  However, you should
%% maintain space for names and addresses so that they will fit in the final
%% (accepted) version.  The ACL 2016 \LaTeX\ style will create a titlebox space of
%% 2.5in for you when {\small\verb|\aclfinalcopy|} is commented out.

%% \subsection{The Ruler}
%% The ACL 2016 style defines a printed ruler which should be presented in the
%% version submitted for review.  The ruler is provided in order that
%% reviewers may comment on particular lines in the paper without
%% circumlocution.  If you are preparing a document without the provided
%% style files, please arrange for an equivalent ruler to
%% appear on the final output pages.  The presence or absence of the ruler
%% should not change the appearance of any other content on the page.  The
%% camera ready copy should not contain a ruler. (\LaTeX\ users may uncomment
%% the {\small\verb|\aclfinalcopy|} command in the document preamble.)


\title{Optimizing a PoS Tag Set for Dependency Parsing}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  {\tt email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  {\tt email@domain}  \\\And
  Third Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  {\tt email@domain} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}

This paper reports on a suite of experiments that evaluates how the linguistic
granularity of part-of-speech tag sets impacts the performance of tagging and
syntactic dependency parsing. Our results show that parsing accuracy can be
significantly improved by introducing more fine-grained morphological
information in the tag set, even if tagger accuracy is compromised. Our taggers
and parsers are  trained and tested using the annotations of the Norwegian
Dependency Treebank.

\end{abstract}

%\section{Credits}

\section{Introduction}
\label{sec:intro}
Part-of-speech (PoS) tagging is an important preprocessing step for many NLP
tasks, such as dependency parsing \cite{Niv:Hal:Kub:07,Haj:Cia:Joh:09}, named
entity recognition \cite{Tjo:DeM:03} and sentiment analysis
\cite{Wil:Wie:Hof:09}. Whereas much effort has gone into the development of
PoS taggers -- to the effect that this task is often considered more or less a
solved task -- considerably less effort has been devoted to the empirical
evaluation of the PoS tag sets themselves. Error analysis of PoS taggers
indicate that, whereas tagging improvement through means of learning algorithm
or feature engineering seems to have reached something of a plateau, linguistic
and empirical assessment of the distinctions made in the PoS tag sets may be a
venue worth investigating further \cite{Man:11}. Clearly, the utility of a PoS
tag set is tightly coupled with the downstream task for which it is performed.
Even so, PoS tag sets are usually employed in a ``one size fits all'' fashion,
regardless of the requirements posed by the task which makes use of this
information.

It is well known that syntactic parsing often benefits from quite fine-grained
morphological distinctions \cite{Zha:Niv:11,See:Kuh:13}. Morphology interacts
with syntax though phenomena such as agreement and case marking, and
incorporating information on morphological properties of words can therefore
often improved parsing performance. However, in a realistic setting where the
aim is to automatically parse raw text, the generation of morphological
information will often require a separate step of morphological analysis that
can be quite costly.

In this paper, we optimize a PoS tag set for the task of data-driven dependency
parsing of Norwegian. We report on a set of experiments where various
morphological distinctions are introduced to the PoS annotations and evaluated
both intrinsically, i.e., in terms of PoS tagging accuracy, and extrinsically,
in terms of parsing accuracy. Our results show that the introduction of
morphological distinctions not present in the original tag set, whilst
compromising tagger accuracy, actually leads to significantly improved parsing
accuracy. This optimization allows us to bypass the additional step of
morphological analysis, framing the whole preprocessing problem as a simple
tagging task.

The article is structured as follows. We start out by reviewing previous work
on tag set evaluation in Section \ref{sec:prev}, while Section \ref{sec:data}
details the treebank that provides the initial gold annotations used for our
experiments. Section \ref{sec:setup} describes the experimental setup used in
our work and Section \ref{sec:optimization} goes on to provide the results from
our tag set optimization. Finally, Section \ref{sec:summary} summarizes our
main findings and discusses some avenues for future work.

\section{Previous Work}
\label{sec:prev}
There has been little previous work dedicated specifically to extrinsic
evaluation of the effects of PoS tag sets on downstream applications.  There
has, however, been some work that evaluates the effects of tag set granularity
on PoS tagging itself. This includes investigation of the effects of tag sets
on PoS tagging for Swedish \cite{Meg:01,Meg:02} and English \cite{Mac:05}.

\newcite{Meg:02} trained and evaluated a range of PoS taggers on the
Stockholm-Umeå Corpus (SUC) \cite{Gus:Har:06}, annotated with a tag set based
on a Swedish version of PAROLE tags totaling 139 tags. Furthermore, the effects
of tag set size on tagging was investigated by mapping the original tag set
into smaller subsets designed for parsing. \newcite{Meg:02} argues that a tag
set with complete morphological tags may not be necessary for all NLP
applications, for instance syntactic parsing. The study found that the smallest
tag set comprising 26 tags yields the lowest tagger error rate. However, for
some of the taggers, augmenting the tag set with more linguistically
informative tags may actually lead to a drop in error rate. \newcite{Meg:02}
argues that this shows that the size of the tag set as well as the type of
information in the tags are crucial factors for tagger performance.
Unfortunately, results for parsing with the various PoS tag sets are not
reported.

Similarly, \newcite{Mac:05} investigated the effects of PoS tag sets on tagger
performance in English, specifically the Wall Street Journal portion of the
Penn Treebank (PTB) \cite{Mar:San:Mar:93}. Based on linguistic considerations,
\newcite{Mac:05} mapped the 45 tags of the original PTB tag set to more
fine-grained tag sets to investigate whether additional linguistic information
could assist the tagger. Experimenting with both lexically and syntactically
conditioned modifications such as distinguishing between count nouns and
noncount nouns and between transitive and intransitive verbs, they found that
more fine-grained tag sets rarely led to improvements in tagger accuracy; the
most successful modification yielded an improvement in tagger accuracy of 0.05
percentage points. They did not find any statistically significant
improvements using linguistically informed distinctions, arguing that their
results do not support the hypothesis that it is possible to achieve
significant performance improvements in PoS tagging by utilizing a
finer-grained tag set.

We argue, however, that it is possible to significantly improve the performance
of the downstream application of syntactic parsing by introducing
linguistically informed, syntactically informative distinctions to a tag set.
We will now turn to the data that provided the basis for our experiments and
outline its morphological and syntactic annotation choices.

\section{The Norwegian Dependency Treebank}
\label{sec:data}
Our experiments are based on the newly developed Norwegian Dependency Treebank
(NDT) \cite{Sol:Skj:Ovr:14}, the first publicly available treebank for
Norwegian. It was developed at the National Library of Norway in collaboration
with the University of Oslo, and contains manually coded syntactic and
morphological annotation for both varieties of Norwegian; 311 000 tokens of
Bokmål and 303 000 tokens of Nynorsk. This paper only reports results for
Bokmål, the main variety. The treebanked material mostly comprise newspaper
text, but also include government reports, parliament transcripts and blog
excerpts. The annotation process was supported by the rule-based Oslo-Bergen
Tagger \cite{Hag:Joh:Nok:00} and then manually corrected by annotators, adding
syntactic dependency analysis to the morphosyntactic annotation.

\paragraph{Morphological Annotation}
\begin{table}
    \centering
    \smaller[0.5]
    \begin{tabular}{@{}ll@{}}
        \toprule
        \textbf{Tag} & \textbf{Description} \\
        \midrule
        \texttt{adj} & Adjective \\
        \texttt{adv} & Adverb \\
        \texttt{det} & Determiner\\
        \texttt{inf-merke} & Infinitive marker \\
        \texttt{interj} & Interjection \\
        \texttt{konj} & Conjunction \\
        \texttt{prep} & Preposition \\
        \texttt{pron} & Pronoun \\
        \texttt{sbu} & Subordinate conjunction \\
        \texttt{subst} & Noun \\
        \texttt{ukjent} & Unknown (foreign word) \\
        \texttt{verb} & Verb \\
        \bottomrule
    \end{tabular}
    \caption{Overview of the original PoS tag set of NDT (excluding punctuation
        tags).}
    \label{ndttagset}
\end{table}

The morphological annotation and PoS tag set of NDT is based on the same
inventory as used by the Oslo-Bergen Tagger \cite{Hag:Joh:Nok:00,Sol:13}, which
in turn is largely based on the work of \newcite{Faa:Lie:Van:97}. The tag set
consists of 12 morphosyntactic PoS tags outlined in Table \ref{ndttagset}, with
7 additional tags for punctuation and symbols. The tag set is thus rather
coarse-grained, with broad categories such as \texttt{subst} (noun) and
\texttt{verb} (verb). The PoS tags are complemented by a large set of
morphological features, providing information about morphological properties
such as definiteness, number and tense.  Selected subsets of these features are
used in our tag set modifications, where the coarse PoS tag of relevant tokens
is concatenated with one or more features to include more linguistic
information in the tags.

\paragraph{Syntactic Annotation}
\begin{table}
    \centering
    \smaller[0.5]
    \begin{tabular}{@{}ll@{}}
        \toprule
        \textbf{Head} & \textbf{Dependent} \\
        \midrule
        Preposition & Prepositional complement \\
        Finite verb & Complementizer \\
        First conjunct & Subsequent conjuncts \\
        Finite auxiliary & Lexical/main verb \\
        Noun & Determiner \\
        \bottomrule
    \end{tabular}
    \caption{Central head-dependent annotation choices in NDT.}
    \label{ndtannotation}
\end{table}

The syntactic annotation choices in NDT are largely based on the Norwegian
Reference Grammar \cite{Faa:Lie:Van:97}. Some central annotation choices are
outlined in Table \ref{ndtannotation}, taken from \newcite{Sol:Skj:Ovr:14},
providing overview of the analyses of syntactic constructions that often
distinguish dependency treebanks, such as coordination and the treatment of
auxiliary and main verbs. The annotations comprise 29 dependency relations,
including \textsc{adv} (adverbial), \textsc{subj} (subject) and \textsc{koord}
(coordination).

\section{Experimental Setup}
\label{sec:setup}
In preparation to conducting our experiments with linguistically motivated tag
set modifications, a concrete setup for the experiments needed to be
established, which is presented in the following.


\paragraph{Data Set Split}
As there was no existing standardized data set split of NDT due to its recent
development, we first needed to define separate sections for training,
development and testing. Our proposed sectioning of the treebank follows a
standard 80-10-10 split. In establishing the split, care has been taken to
preserve contiguous texts in the various sections while also keeping them
balanced in terms of genre.

Our defined split into sections for training, development testing, and held-out
testing will be distributed with the future releases of the treebank, but
details for replicating the split will also be made available at a companion website
for the final version of the paper.
% Our proposed split has already been used in the Norwegian contribution to the
% Universal Dependencies project \cite{Ovr:Hoh:16}.

\paragraph{Tagger}
As our experiments during development required many repeated cycles of training and
testing for the different modified tag sets, we sought a PoS tagger that is both
reasonably fast and accurate. There is a often a considerable trade-off between
the two factors, as the most accurate taggers tend to suffer in terms of speed
due to their complexity. However, a tagger that achieves both close to
state-of-the-art accuracy as well as very high speed is TnT \cite{Bra:00}. TnT
was furthermore recently used to evaluate the recently proposed universal tag
set \cite{Pet:Das:McD:12}. The sum of these factors led to TnT being the tagger
of choice for our experiments.

\paragraph{Parser}
In choosing a syntactic parser for our experiments, we considered previous work
on dependency parsing of Norwegian, specifically that of
\newcite{Sol:Skj:Ovr:14}, who found the Mate parser \cite{Boh:10} to have the
best performance for parsing of NDT. Furthermore, recent dependency parser
comparisons \cite{Cho:Tet:Ste:15} showed that Mate performed very well on
parsing of English, outperforming a range of contemporary state-of-the-art
parsers. We will be using Mate for gauging the effects of the tag set
modifications in our experiments.

\paragraph{Tag Set Mapping}
The tag set modifications are realized by mapping the existing tags to new,
more fine-grained tags "based" on associated morphological features to be
included in specified tags. The procedure maps the relevant existing tags to
new, more fine-grained tags including more relevant morphological features for
the applicable tokens, i.e., tokens that are assigned said tag and feature(s)
in the gold standard data. Hence, we are in actuality altering the gold
standard tags by the addition of more relevant linguistic information,
producing new gold standard annotations of higher quality.

% fixme: tror nok dette bør flyttes og kortes ned. kan bakes inn med det som
% står under "Tag Set Mapping".
Our approach is somewhat semi-automatic in that we employ a "hybrid"
combination of manual annotation and automatic labeling in our experiments. Our
initial tags are gold standard, and using linguistic insight coupled with
computational considerations, we introduce new gold standard distinctions to
the tag set. The data sets with these tags are run through a pipeline with
automatically assigned tags in both training and testing, where the most
promising modifications are used "further". Hence, the tag set modifications
are not deterministic, nor do we try all possible combination; we only
experiment with linguistically motivated distinctions.

As we want to investigate how we can improve the linguistic quality of a tag
set, we will only consider tag set modifications we deem linguistically
sensible.
%This is done by concatenating the original tag with the
%specified features for all applicable tokens

%contains the set of features in its morphological features.

\paragraph{Evaluation}
To evaluate tagging and parsing with the various tag set modifications in our
experiments, we employed commonly used evaluation metrics. Tagging is evaluated
in terms of accuracy (reported by the TnT-included \texttt{tnt-diff} script;
denoted \emph{Acc} in the following tables), while labeled attachment score
(LAS) and unlabeled attachment score (UAS) are computed by the
\texttt{eval.pl}\footnote{\url{http://ilk.uvt.nl/conll/software.html}} script
(used in the CoNLL shared tasks) to evaluate the parsing.

\paragraph{Baseline}
As a point of reference for the PoS tagging, we will be reporting the commonly
used most-frequent-tag baseline, henceforth MFT. This involves labeling each
word with the tag it was assigned most frequently in the training data. All
unknown words, i.e., words not seen in the training data, are assigned the tag
most frequently assigned to words seen only once. The rationale is that we
might expect unknown and infrequent words to have similar properties given that
they both occur rarely.

\paragraph{Tags \& Features} % <-- fixme: rename?
As we seek to quantify the effects of PoS tagging in a realistic setting, i.e.,
in application to raw text, we choose to evaluate the parser on automatically
assigned PoS tags. For training, however, we have two options: using either
gold standard or automatically assigned tags. In order to settle on a
configuration, we conducted experiments with training on both gold standard
tags and automatically assigned tags to see how the performance differs. The
results of these experiments, shown in Table \ref{tagconfigeval}, reveal that
the combination of training and testing on automatic tags is clearly superior
to training on gold standard tags and testing on automatic tags. Consequently,
the parser is both trained and tested on automatically assigned tags in the
remainder of our experiments.

\begin{table}
    \centering
    \smaller[0.5]
    \begin{tabular}{@{}llll@{}}
        \toprule
        \textbf{Training} & \textbf{Testing} & \textbf{LAS} & \textbf{UAS} \\
        \midrule
        Gold & Gold & 90.15\% & 92.51\% \\
        Gold & Auto & 85.68\% & 88.98\% \\
        Auto & Auto & 87.01\% & 90.19\% \\
        \bottomrule
    \end{tabular}
    \caption{Results of parsing with Mate using the various tag configurations,
        either using gold standard tags or automatically assigned from TnT.
        \emph{Gold} denotes gold standard tags, \emph{Auto} denotes
        automatically assigned tags from TnT.}
    \label{tagconfigeval}
\end{table}

Though some parsers make use of morphological features, % fixme: status for mate?
we removed all morphological features beyond the PoS tags in order to simulate
a realistic setting.  Moreover, it is crucial that we remove these features
when working with automatically assigned tags, as such features would be
provided by the gold standard.

%For instance, if a verb token is erroneously tagged as a noun, we could potentially
%have a noun token with verbal features such as tense, which markedly obfuscates
%the training and parsing. Another important aspect is that we want to isolate
%the effect of PoS tags, necessitating the exclusion of morphological features.

In the following, we report on a set of experiments which evaluate increasingly
fine-grained PoS tag sets. The PoS tag sets are motivated by morphosyntactic
properties of Norwegian and are evaluated in terms of both tagger and parser
accuracy.

\section{Tag Set Optimization}
\label{sec:optimization}
By introducing more fine-grained linguistically motivated distinctions in a tag
set, we increase the linguistic information represented in the tags, which may
assist the parser in recognizing and generalizing syntactic patterns.
We would then also increase the complexity of the tagging task though,
which can be expected to lead to a drop in tagger accuracy.
However, the best tagging, evaluated in isolation, does not necessarily lead to the
best parse, hence it is interesting to investigate how tag set modifications
may affect this interplay.


\subsection{Baseline Experiments}
In an initial round of experiments, we concatenated the tag of each token with
its full set of morphological features, thereby mapping the original tag set to a
new maximally fine-grained tag set given the annotations available in the
treebank. This resulted in a total of 368 tags,
hereafter referred to as the \emph{full} tag set.
The two initial tag sets, i.e., the original tag set comprising 19 tags and the
full tag set comprising 368 tags, thus represent two extremes in terms of
granularity.
To establish some initial points of reference for how tag set granularity affects the
performance of tagging and parsing on NDT, we trained and tested a full pipeline with both of
these initial tags sets. The results are reported in Table \ref{inittagseteval}.
Unsurprisingly, we see that the tagger accuracy
plummets when we move from the original to the full tag set. The MFT
baseline for the original tag set is 94.14\%, while it drops by almost 9
percentage points to 85.15\% for the full tag set. TnT reports an accuracy of
97.47\% on the original tag set, which is reduced to 93.48\% for the full tag
set. These results confirm our hypothesis that the very high level of linguistic
information
in the full, fine-grained tag set comes at the expense of reduced tagger
performance.  In spite of this, however, we see that the additional information
in the full tag set still improves the parser performance. With the original tag set, Mate
yields 87.01\% LAS and 90.19\% UAS, which increases to 87.15\% and
90.39\%, respectively, using the full tag set. As we are looking for
linguistically informed distinctions that improve the syntactic parsing, these
results are promising and indicate that additional linguistic
information assists syntactic parsing, motivating the optimization of the
existing PoS tag set.

\begin{table}
    \centering
    \smaller[0.5]
    \begin{tabular}{@{}lllll@{}}
        \toprule
        \textbf{Tag Set} & \textbf{MFT} & \textbf{Acc} &
        \textbf{LAS} & \textbf{UAS} \\
        \midrule
        Original & \textbf{94.14\%} & \textbf{97.47\%} & 87.01\% & 90.19\% \\
        Full & 85.15\% & 93.48\% & \textbf{87.15\%} & \textbf{90.39\%} \\
        \bottomrule
    \end{tabular}
    \caption{Results of tagging and parsing our development section of NDT with
      the two initial tag sets. From left to right we report the tagger
      accuracy of the most-frequent-tag baseline, the tagger accuracy of TnT,
      and labeled / unlabeled attachment scores for the Mate parser.}
    \label{inittagseteval}
\end{table}

\subsection{Tag Set Experiments}
We modified the tags for nouns (\texttt{subst}), verbs (\texttt{verb}),
adjectives (\texttt{adj}), determiners (\texttt{det}) and pronouns
(\texttt{pron}) in NDT by appending selected sets of morphological features to
each tag in order to increase the linguistic information expressed by the tags.
For each tag in turn, we first experiment with each of the available features in
isolation before testing various combinations in order to see how the features
might interact. We base our choices of combinations on how promising the
features are and what we deem worth investigating in terms of linguistic utility.

The morphological properties of the various parts-of-speech are reflected in
the morphological features associated with the respective PoS tags. For
instance, as nouns in Norwegian can take on gender, definiteness and number,
the treebank operates with features for gender, definiteness and number
complementing the \texttt{subst} tag. In addition to morphological properties
such as definiteness, tense and number, all classes except for verbs have a
\emph{type} feature that provides information about the subtype of the PoS,
e.g., whether a noun is common or proper.

\paragraph{Nouns}
In Norwegian, nouns are assigned gender (feminine, masculine or neuter),
definiteness (definite or indefinite) and number (singular or plural). There is
agreement in gender, definiteness and number between nouns and their modifiers
(adjectives and determiners). Additionally, NDT has a separate \emph{case}
feature for distinguishing nouns in genitive case. Genitive case marks
possession, hence nouns marked with genitive case are quite different from
other nouns, taking a noun phrase as complement. Distinguishing on type is
useful and informative, as evident by the presence of separate tags for proper
and common nouns in many tag sets, such as those of Penn Treebank and
Stockholm-Umeå corpus.

%As nouns constitute the largest class in the treebank by far, the effects of
%the tag set modifications are greatest for noun tokens in terms of overall
%change in performance.
The results of experimenting with tag set modifications
for nouns are shown in Table \ref{substresults} and reveal that, apart from
case, none of the tag set modifications improve the tagging. However, they all
give rise to increases in parser accuracy scores.
The most informative features are definiteness, which
leads to an increase in LAS by 1.26 percentage points to 88.27\%, and type,
yielding an LAS of 88.07\%. Turning to combinations of features, we found that
the combination of type and case, as well as type and definiteness, were the
most promising, which led us to combine type, case and definiteness in a final
experiment, resulting in LAS of 88.81\% and UAS of 91.73\%, constituting large
improvements from parsing with the original tag set, of 1.80 percentage points
and 1.54 percentage points, respectively.

\begin{table}
    \centering
    \smaller[1]
    \begin{tabular}{@{}llll@{}}
        \toprule
        \textbf{Feature(s)} & \textbf{Acc} & \textbf{LAS} & \textbf{UAS}
        \\
        \midrule
        --- & 97.47\% & 87.01\% & 90.19\% \\
        Case & \textbf{97.48\%} & 87.63\% & 90.72\% \\
        Definiteness & 97.00\% & 88.27\% & 91.42\% \\
        Gender & 96.09\% & 87.21\% & 90.36\% \\
        Number & 96.37\% & 87.97\% & 91.00\% \\
        Type & 96.92\% & 88.07\% & 91.11\% \\
        Case \& definiteness & 97.03\% & 88.39\% & 91.44\% \\
        Type \& case & 96.92\% & 88.46\% & 91.51\% \\
        Type \& definiteness & 96.99\% & 88.44\% & 91.48\% \\
        %Type \& number & 96.37\% & 87.95\% & 90.95\% \\
        Type, case \& definiteness & 97.05\% & \textbf{88.81\%} &
        \textbf{91.73\%} \\
        %Type, definiteness \& number & 96.46\% & 88.06\% & 91.12\% \\
        \bottomrule
    \end{tabular}
    \caption{Results of experiments with modified PoS tags for nouns.}
    \label{substresults}
\end{table}

\paragraph{Verbs}
Verbs are inflected for tense (infinitive, present, preterite or past perfect)
in Norwegian and additionally exhibit mood (imperative or indicative; also
conjunctive, however, it is very uncommon and does not occur in the treebank)
and voice (active or passive). Note that both voice and mood have only a single
value in the treebank; \texttt{pass} (passive) and \texttt{imp} (imperative),
respectively. Verbs which are not passive are implicitly active, and verbs
which are not imperative are in indicative mood.

Table \ref{verbresults} presents the results from tagging and parsing with
modified verb tags. Imperative clauses are fundamentally different from
indicative clauses as they lack an overt subject, which is reflected in the
fact that mood is the only feature leading to an increase in LAS, with a
reported LAS of 87.04\%. Although voice is a very distinguishing property for
verbs, and passive clauses are very different from active clauses, introducing
this distinction in the tag set leads to a drop in LAS of 0.05 percentage
points, while distinguishing between the various tenses yields an LAS of
86.97\%. Combining the two most promising features of mood and tense resulted
in an LAS of 87.12\% and UAS of 90.31\%.

In an additional experiment, we mapped the verb tenses (and mood, in the case
of imperative) to finiteness. All verbs have finiteness, hence this distinction
has broad coverage. This mapping is syntactically grounded as finite verbs and
nonfinite verbs appear in completely different syntactic constructions, and
proved to greatly improve the parsing, as we saw the highest parser accuracy
scores of 87.30\% for LAS and 90.43\% for UAS, 0.29 and 0.24 percentage points
higher than the baseline, respectively. This coincides with the observations
seen for Swedish in \newcite{Ovr:08}, where finiteness was found
to be a very beneficial linguistic feature for parsing.

\begin{table}
    \centering
    \smaller[0.5]
    \begin{tabular}{@{}llll@{}}
        \toprule
        \textbf{Feature(s)} & \textbf{Acc} & \textbf{LAS} & \textbf{UAS} \\
        \midrule
        --- & \textbf{97.47\%} & 87.01\% & 90.19\% \\
        Mood & 97.43\% & 87.04\% & 90.19\% \\
        Tense & 97.30\% & 86.97\% & 90.18\% \\
        Voice & 97.45\% & 86.96\% & 90.09\% \\
        Mood \& tense & 97.31\% & 87.12\% & 90.31\% \\
        Voice \& tense & 97.28\% & 86.99\% & 90.15\% \\
        Mood, tense \& voice & 97.27\% & 86.83\% & 90.05\% \\
        Finiteness & 97.35\% & \textbf{87.30\%} & \textbf{90.43\%} \\
        \bottomrule
    \end{tabular}
    \caption{Results of experiments with modified PoS tags for verbs.}
    \label{verbresults}
\end{table}

\paragraph{Adjectives}
Adjectives agree with the noun they modify in terms of gender, number and
definiteness in Norwegian. Furthermore, adjectives are inflected for
degree (positive, comparative or superlative).

In Table \ref{adjresults}, we report the results of modifying the \texttt{pron}
tag in NDT. All features except for number lead to increases in parser accuracy
scores, the most successful of which is degree with a reported LAS of 87.29\%,
while distinguishing adjectives on definiteness yields an LAS of 87.14\% and
introducing the distinction of gender leads to LAS of 87.10\%.

%Combining the most promising features, we
%found that none of the combinations surpass the LAS with the distinction of
%degree alone. Definiteness and degree with an LAS of 87.23\% and definiteness
%and number with an LAS of 87.27\% and UAS identical to that of degree alone.

Turning to combinations of features, definiteness and number achieve the best
parser accuracy scores, very close to those of degree, with 0.02 percentage
points lower LAS and identical UAS. Adjectives agree with their head noun and
determiner in definiteness and number, making this an expected improvement. The
combination of definiteness and degree is also quite promising, obtaining LAS
of 87.23\% and UAS of 90.39\%. It is interesting that none of the combinations
surpass the experiment with degree alone, which indicates that degree does not
interact with the other features in any syntactically significant way.

\begin{table}
    \centering
    \smaller[0.5]
    \begin{tabular}{@{}llll@{}}
        \toprule
        \textbf{Feature(s)} & \textbf{Acc} & \textbf{LAS} & \textbf{UAS}
        \\
        \midrule
        --- & \textbf{97.47\%} & 87.01\% & 90.19\% \\
        Definiteness & 96.84\% & 87.14\% & 90.29\% \\
        Degree & 97.41\% & \textbf{87.29\%} & \textbf{90.44\%} \\
        Gender & 96.89\% & 87.10\% & 90.25\% \\
        Number & 96.71\% & 86.99\% & 90.10\% \\
        Type & 97.40\% & 87.11\% & 90.25\% \\
        Definiteness \& degree & 96.81\% & 87.23\% & 90.39\% \\
        Definiteness \& gender & 96.31\% & 87.18\% & 90.39\% \\
        Definiteness \& number & 96.78\% & 87.27\% & \textbf{90.44\%} \\
        %Degree \& gender & 96.87\% & 87.00\% & 90.16\% \\
        %Degree \& number & 96.76\% & 87.13\% & 90.26\% \\
        %Definiteness, degree \& number & 96.81\% & 87.14\% & 90.30\% \\
        \bottomrule
    \end{tabular}
    \caption{Results of experiments with modified PoS tags for adjectives.}
    \label{adjresults}
\end{table}

\paragraph{Determiners}
Like adjectives, determiners in Norwegian agree with the noun they modify in
terms of gender, number and definiteness. We do not report results from
combinations of features for determiners, as the features could not be combined
in any meaningful way.
%VPossessive pronouns are
%treated/analyzed as determiners in NDT.

%For instance, determiners in plural never have marked definiteness, hence this
%combination would only apply to determiners in singular and roughly correspond
%to the distinction on definiteness alone. Moreover, determiners in plural are
%not distinguished in terms of gender (thus ruling out the combination of number
%and gender), neither are definite determiners. Another aspect taken into
%consideration is that the most promising distinction, definiteness, applies to
%such a small number of tokens that more fine-grained distinctions would be
%overly sparse.

The results from the experiments with determiners are shown in Table
\ref{detresults}. Introducing the distinction of type (demonstrative,
amplifier, quantifier, possessive or interrogative) led to an increase in
tagger accuracy of 0.14 percentage points to 97.61\%, while marginally
impacting the parsing, with LAS of 87.00\%, 0.01 percentage points below that
of the original tag set.  The increase in tagger accuracy when introducing the
distinction of type is noteworthy, as we expected the finer granularity to lead
to a decrease in accuracy. This serves to indicate that more fine-grained
distinctions for determiners, which is a quite disparate category in the
treebank, may be quite useful for tagging.

%However, as it has negative impact
%on parsing, we can conclude that the type of a determiner does not assist in
%generalizing syntactic patterns. Most determiners, regardless of type, appear
%in the same syntactic constructions (i.e., before a noun or noun phrase).

Gender, on the other hand, improved the parsing (87.09\% LAS), but complicated
the tagging, as the various genders are often difficult to differentiate,
especially so in the case of masculine and feminine, which share many of the
same determiners. The number of a determiner, i.e., singular or plural, led to
a small increase in tagger accuracy and LAS, while marginally lower UAS of
90.18\%, 0.01 percentage points lower than that of the original tag set. The
introduction of definiteness to the determiners led to the best parsing
results, LAS of 87.30\% and UAS of 90.42\%, while also increasing the tagger
accuracy slightly. The increase in LAS and UAS is rather interesting, as there
are only 121 determiner tokens with marked definiteness in the development
data. As this accounts for a very small number of tokens, we did not consider
further fine-grained modifications with definiteness. This serves to indicate
that tokens with overt definiteness have noticeable impact on the syntactic
parsing and that distinguishing on definiteness is very useful.

\begin{table}
    \centering
    \smaller[0.5]
    \begin{tabular}{@{}llll@{}}
        \toprule
        \textbf{Feature} & \textbf{Acc} & \textbf{LAS} & \textbf{UAS} \\
        \midrule
        --- & 97.47\% & 87.01\% & 90.19\% \\
        Definiteness & 97.49\% & \textbf{87.30\%} & \textbf{90.42\%} \\
        Gender & 97.28\% & 87.09\% & 90.31\% \\
        Number & 97.49\% & 87.04\% & 90.18\% \\
        Type & \textbf{97.61\%} & 87.00\% & 90.11\% \\
        \bottomrule
    \end{tabular}
    \caption{Results of experiments with modified PoS tags for determiners.}
    \label{detresults}
\end{table}

\paragraph{Pronouns}
Pronouns in Norwegian are personal, reciprocal, reflexive and interrogative.
They can furthermore exhibit gender, number and person, while personal pronouns
can be distinguished on case (either accusative or nominative).

The results in Table \ref{pronresults} show that number, person and type are
the most informative features for parsing, with LAS of 87.21\%, 87.22\% and
87.19\%, respectively. However, when combining number and person, we observe a
drop by more than 0.2 percentage points, indicating that these features do not
interact in any syntactically distinctive way. The most interesting observation
is that all experiments exceed the tagging accuracy of the original tag set,
the most improved being the most fine-grained distinction, namely type, case
and number combined, obtaining a tagger accuracy of 97.52\%. This shows that
the introduction of more fine-grained distinctions for pronouns aids the PoS
tagger in disambiguating ambiguous words. While case alone yields an LAS of
87.08\%, we found that the combination of type and case, which is the most
successful experiment in terms of parser performance, yields the second highest
tagging accuracy of 97.51\%. Pronouns of different type and personal pronouns
of different case exhibit quite different properties and appear in different
constructions. Pronouns in nominative case (i.e., subjects) primarily occur
before the main verb, while pronouns in accusative case (i.e., objects) occur
after the main verb, as Norwegian exhibits so-called V2 word order, requiring
that the finite verb of a declarative clause appears in the second position,
hence its name. The combination of type and number comes in close to the
performance of type and case, with LAS of 87.27\% and UAS identical to that of
type and case.

\begin{table}
    \centering
    \smaller[0.5]
    \begin{tabular}{@{}llll@{}}
        \toprule
        \textbf{Feature(s)} & \textbf{Acc} & \textbf{LAS} & \textbf{UAS} \\
        \midrule
        --- & 97.47\% & 87.01\% & 90.19\% \\
        Case & 97.50\% & 87.08\% & 90.21\% \\
        Gender & 97.48\% & 87.06\% & 90.23\% \\
        Number & 97.49\% & 87.21\% & 90.33\% \\
        Person & 97.49\% & 87.22\% & 90.32\% \\
        Type & 97.48\% & 87.19\% & 90.40\% \\
        Number \& person & 97.49\% & 96.98\% & 90.16\% \\
        Type \& case & 97.51\% & \textbf{87.30\%} & \textbf{90.41\%} \\
        Type \& number & 97.49\% & 87.27\% & \textbf{90.41\%} \\
        Type \& person & 97.49\% & 87.00\% & 90.14\% \\
        Type, case \& number & \textbf{97.52\%} & 87.11\% & 90.36\% \\
        \bottomrule
    \end{tabular}
    \caption{Results of experiments with modified PoS tags for pronouns.}
    \label{pronresults}
\end{table}

\subsection{Optimized Tag Set}
\begin{table*}[ht]
    \centering
    \smaller[0.5]
    \begin{tabular}{@{}llllll@{}}
        \toprule
        \textbf{Category} & \textbf{Feature(s)} & \textbf{MFT} &
        \textbf{Acc} & \textbf{LAS} & \textbf{UAS} \\
        \midrule
        \emph{Original} & --- & 94.14\% & 97.47\% & 87.01\% & 90.19\% \\
        Noun & Type, case \& definiteness & 89.61\% & 97.05\% & 88.81\% &
        91.73\% \\
        Verb & Finiteness & 93.72\% & 97.35\% & 87.30\% & 90.43\% \\
        Adjective & Degree & 94.13\% & 97.41\% & 87.29\% & 90.44\% \\
        Determiner & Definiteness & 94.13\% & 97.49\% & 87.30\% & 90.42\% \\
        Pronoun & Type \& case & 94.12\% & 97.51\% & 87.30\% & 90.41\% \\
        \bottomrule
    \end{tabular}
    \caption{Results of tagging and parsing with the most successful tag set
        modification for each category.}
    \label{respectiveresults}
\end{table*}

The most successful tag set modification for each PoS and the results from
tagging and parsing with the respective modifications are seen in Table
\ref{respectiveresults}. Nouns benefit by far the most from the introduction of
more fine-grained linguistically motivated distinctions, with an LAS of 88.81\%
and UAS of 91.73\% when distinguishing on type, case and definiteness. We
observe that the most promising tag set modifications for verbs, adjectives,
determiners and pronouns all reach LAS of \textasciitilde 87.30\% and UAS of
\textasciitilde 90.40\%. To investigate the overall effect of these tag set
modifications, we tested each of the improvements in parser accuracy scores
from that of the original tag set for statistical significance using Dan
Bikel's randomized parsing evaluation comparator script\footnote{Available as
    \texttt{compare.pl} at \url{http://ilk.uvt.nl/conll/software.html}}, as
used in the CoNLL shared tasks. For the most successful tag set modification
for each of the categories seen in Table \ref{respectiveresults}, the
difference in LAS from the original tag set is statistically significant at
significance level 0.05 (\emph{p}-value < 0.05), as are all differences in UAS,
except for verbs with finiteness (\emph{p}-value 0.15) and pronouns with type
and case (\emph{p}-value 0.06).

An overview of the tags in the optimized tag set can be seen in Table
\ref{optimizedtagset}, comprising three new tags for adjectives, two for
determiners, six for pronouns, seven for nouns and two for verbs, totaling 20
tags. Appending these to the original tag set comprising 19 tags, we reach a
total of 39 tags for NDT.

\begin{table}
    \centering
    \smaller[0.5]
    \begin{tabular}{@{}ll@{}}
        \toprule
        \textbf{Tag} & \textbf{Description} \\
        \midrule
        \texttt{adj|komp} & Comparative adjective \\
        \texttt{adj|pos} & Positive adjective \\
        \texttt{adj|sup} & Superlative adjective \\
        \texttt{det|be} & Definite determiner \\
        \texttt{det|ub} & Indefinite determiner \\
        \texttt{pron|pers} & Personal pronoun \\
        \texttt{pron|pers|akk} & Personal pronoun, accusative \\
        \texttt{pron|pers|nom} & Personal pronoun, nominative \\
        \texttt{pron|refl} & Reflexive pronoun \\
        \texttt{pron|res} & Reciprocal pronoun \\
        \texttt{pron|sp} & Interrogative pronoun \\
        \texttt{subst|appell} & Common noun \\
        \texttt{subst|appell|be} & Common noun, def. \\
        \texttt{subst|appell|be|gen} & Common noun, def., genitive \\
        \texttt{subst|appell|ub} & Common noun, indef. \\
        \texttt{subst|appell|ub|gen} & Common noun, indef., genitive \\
        \texttt{subst|prop} & Proper noun \\
        \texttt{subst|prop|gen} & Proper noun, genitive \\
        \texttt{verb|fin} & Finite verb \\
        \texttt{verb|infin} & Nonfinite verb \\
        \bottomrule
    \end{tabular}
    \caption{Overview of the optimized tag set.}
    \label{optimizedtagset}
\end{table}

\paragraph{Final Evaluation}
In Table \ref{finalresults}, we show the results of parsing with the optimized
tag set on the held-out test data and the development data, compared to the
results obtained with the original tag set. We see significant improvements
from the original tag set on both the development data and the held-out test
data set. The improvement in LAS on the development data is 1.86 percentage
points, while 1.91 percentage points on the held-out test data. These results
indicate that the additional linguistic information in the tags of our
optimized tag set greatly aids syntactic parsing and that optimizing an
existing PoS tag set for a downstream application can be useful and beneficial.

\begin{table}
    \centering
    \smaller[0.5]
    \begin{tabular}{@{}llllll@{}}
        \toprule
        \textbf{Data} & \textbf{Tag Set} & \textbf{MFT} & \textbf{Acc} &
        \textbf{LAS} & \textbf{UAS} \\
        \midrule
        \multirow{2}{*}{Dev}
        & Original & \textbf{94.14\%} & \textbf{97.47\%} & 87.01\% & 90.19\% \\
        %Full & 85.15\% & 93.48\% & 87.15\% & 90.39\% \\
        & Optimized & 85.15\% & 96.85\% & \textbf{88.87\%} & \textbf{91.78\%} \\
        \midrule
        \multirow{2}{*}{Test}
        & Original & \textbf{94.22\%} & \textbf{97.30\%} & 86.64\% & 90.07\% \\
        %& Full & 84.27\% & 92.79\% & 87.03\% & 90.16\% \\
        & Optimized & 88.08\% & 96.35\% & \textbf{88.55\%} & \textbf{91.41\%} \\
        \bottomrule
    \end{tabular}
    \caption{Results of tagging and parsing with the optimized tag set,
        compared to the initial tag sets. Trained and tested using
        automatically assigned tags from TnT.}
    \label{finalresults}
\end{table}

%\section{Optimized Pipeline}
%\label{sec:pipeline}

\section{Summary and Future Work}
\label{sec:summary}
The improvements in parser performance with our optimized tag set indicate that
a more fine-grained PoS tag set may assist syntactic parsers in recognizing and
generalizing syntactic patterns, while potentially compromising the performance
of PoS taggers.

There are several aspects of this thesis that can be further explored in future
work, including extrinsic evaluation of the effects of PoS tag sets on other
downstream NLP applications besides parsing, such as sentiment analysis and
named entity recognition. These applications often require tagged data, but are
markedly different from syntactic parsing, hence the evaluation would involve
investigating an entirely different aspect of the effects of tag set
granularity.

% \section*{Acknowledgments}

\bibliographystyle{acl2016}
\bibliography{references}
% \appendix
%\section{Supplemental Material}
%\label{sec:supplemental}

\end{document}
